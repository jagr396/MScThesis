{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Función para solicitar y obtener el contenido de una página\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Función para completar una URL relativa\n",
    "def complete_url(relative_url):\n",
    "    if not relative_url.startswith('http'):\n",
    "        return f'https://sitllx.diputados.gob.mx/{relative_url}'\n",
    "    return relative_url\n",
    "\n",
    "# Función para extraer la información académica\n",
    "def extract_education(soup):\n",
    "    education_data = []\n",
    "    education_rows = soup.find_all('tr', class_='textoNegro')\n",
    "    for row in education_rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) == 3:  # Grado, campo de estudio, años\n",
    "            education_data.append(f\"{cells[0].text.strip()}: {cells[1].text.strip()} ({cells[2].text.strip()})\")\n",
    "    return ' | '.join(education_data)\n",
    "\n",
    "# Función para extraer los enlaces a las iniciativas políticas\n",
    "def extract_policy_links(soup):\n",
    "    policy_links = soup.select('td.Estilo51 a.linkBlancoSin')\n",
    "    return [complete_url(a['href']) for a in policy_links]\n",
    "\n",
    "# Función para extraer las políticas de cada periodo activo\n",
    "def extract_policies(policy_links):\n",
    "    policies = []\n",
    "    for link in policy_links:\n",
    "        policies_page = fetch_page(link)\n",
    "        policies.extend(extract_policy_data(policies_page))\n",
    "    return ' | '.join(policies)\n",
    "\n",
    "# Función para extraer la información de las políticas de cada enlace\n",
    "def extract_policy_data(policy_soup):\n",
    "    policy_data = []\n",
    "    policy_rows = policy_soup.select('td.Estilo69 span.Estilo71')\n",
    "    for policy_row in policy_rows:\n",
    "        policy_text = policy_row.get_text(strip=True)\n",
    "        if policy_text:\n",
    "            policy_data.append(policy_text)\n",
    "    return policy_data\n",
    "\n",
    "# Función para extraer la información de cada diputado\n",
    "def extract_deputy_info(deputy_url):\n",
    "    soup = fetch_page(deputy_url)\n",
    "    education = extract_education(soup)\n",
    "    policy_links = extract_policy_links(soup)\n",
    "    policies = extract_policies(policy_links)\n",
    "    return education, policies\n",
    "\n",
    "# URL inicial con la lista de diputados\n",
    "base_url = 'https://sitllx.diputados.gob.mx/listado_diputados_gpnp.php?tipot=TOTAL'\n",
    "\n",
    "# Obtener la lista de diputados y sus URLs\n",
    "deputies_list = [(dep.text, complete_url(dep['href'])) for dep in fetch_page(base_url).select('td > a.linkVerde')]\n",
    "\n",
    "# Usar ThreadPoolExecutor para extraer la información de manera concurrente\n",
    "deputies_info = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    future_to_deputy = {executor.submit(extract_deputy_info, url): name for name, url in deputies_list}\n",
    "    for future in concurrent.futures.as_completed(future_to_deputy):\n",
    "        deputy_name = future_to_deputy[future]\n",
    "        try:\n",
    "            education, policies = future.result()\n",
    "            deputies_info.append({\n",
    "                'Name': deputy_name,\n",
    "                'Education': education,\n",
    "                'Policies': policies\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {deputy_name}: {e}\")\n",
    "\n",
    "# Crear un DataFrame con la información extraída\n",
    "df = pd.DataFrame(deputies_info)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Función para realizar la solicitud y obtener el contenido de una página\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Función para completar una URL relativa\n",
    "def complete_url(relative_url):\n",
    "    if not relative_url.startswith('http'):\n",
    "        return f'https://sitllx.diputados.gob.mx/{relative_url}'\n",
    "    return relative_url\n",
    "\n",
    "# Función para extraer la información académica\n",
    "def extract_education(soup):\n",
    "    education_data = []\n",
    "    # Se busca la sección de escolaridad basada en el título de la sección\n",
    "    education_section = soup.find('td', class_='TitulosVerde', string='ESCOLARIDAD')\n",
    "    if education_section:\n",
    "        # Se buscan todos los elementos 'tr' después del título de escolaridad\n",
    "        education_rows = education_section.find_all_next('tr', limit=3)  # Asumimos que hay 3 filas de escolaridad\n",
    "        for row in education_rows:\n",
    "            # Se extrae el texto de cada celda 'td' dentro del 'tr' y se ignora la primera celda vacía\n",
    "            education_data.append(' '.join(td.get_text(strip=True) for td in row.find_all('td', class_='textoNegro')[1:]))\n",
    "    return ' | '.join(education_data)\n",
    "\n",
    "# Función para extraer los enlaces a las iniciativas políticas\n",
    "def extract_policy_links(soup):\n",
    "    return [complete_url(a['href']) for a in soup.select('td.Estilo51 a.linkBlancoSin')]\n",
    "\n",
    "# Función para extraer la información de las políticas propuestas\n",
    "def extract_policies(policy_links):\n",
    "    policies_data = []\n",
    "    for link in policy_links:\n",
    "        policy_page_soup = fetch_page(link)\n",
    "        # Se extraen las descripciones de las políticas de las celdas específicas\n",
    "        policies_rows = policy_page_soup.select('table[valign=\"top\"] > tr > td[valign=\"top\"].Estilo69')\n",
    "        for row in policies_rows:\n",
    "            policy_description = row.select_one('span.Estilo71')\n",
    "            if policy_description:\n",
    "                policies_data.append(policy_description.get_text(strip=True))\n",
    "    return ' | '.join(policies_data)\n",
    "\n",
    "# Función para extraer la información de cada diputado\n",
    "def extract_deputy_info(deputy_url):\n",
    "    soup = fetch_page(deputy_url)\n",
    "    education = extract_education(soup)\n",
    "    policy_links = extract_policy_links(soup)\n",
    "    policies = extract_policies(policy_links)\n",
    "    return {'Education': education, 'Policies': policies}\n",
    "\n",
    "# URL inicial con la lista de diputados\n",
    "base_url = 'https://sitllx.diputados.gob.mx/listado_diputados_gpnp.php?tipot=TOTAL'\n",
    "\n",
    "# Obtener la lista de diputados y sus URLs\n",
    "deputies_list = [(dep.text, complete_url(dep['href'])) for dep in fetch_page(base_url).select('td > a.linkVerde')]\n",
    "\n",
    "# Configurar el ThreadPoolExecutor para extraer la información de manera concurrente\n",
    "deputies_info = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    future_to_deputy = {executor.submit(extract_deputy_info, deputy_data[1]): deputy_data[0] for deputy_data in deputies_list}\n",
    "    for future in concurrent.futures.as_completed(future_to_deputy):\n",
    "        deputy_name = future_to_deputy[future]\n",
    "        try:\n",
    "            deputy_info = future.result()\n",
    "            deputies_info.append({\n",
    "                'Name': deputy_name,\n",
    "                **deputy_info\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {deputy_name}: {e}\")\n",
    "\n",
    "# Crear DataFrame de pandas con la información extraída\n",
    "df = pd.DataFrame(deputies_info)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Función para realizar la solicitud y obtener el contenido de una página\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Función para completar una URL relativa\n",
    "def complete_url(relative_url):\n",
    "    if not relative_url.startswith('http'):\n",
    "        return f'https://sitllx.diputados.gob.mx/{relative_url}'\n",
    "    return relative_url\n",
    "\n",
    "# Función para extraer la información académica\n",
    "def extract_education(soup):\n",
    "    education_data = []\n",
    "    # Se busca la sección de escolaridad basada en el título de la sección\n",
    "    education_section = soup.find('td', class_='TitulosVerde', string='ESCOLARIDAD')\n",
    "    if education_section:\n",
    "        # Se buscan todos los elementos 'tr' después del título de escolaridad\n",
    "        education_rows = education_section.find_all_next('tr', limit=3)  # Asumimos que hay 3 filas de escolaridad\n",
    "        for row in education_rows:\n",
    "            # Se extrae el texto de cada celda 'td' dentro del 'tr' y se ignora la primera celda vacía\n",
    "            education_data.append(' '.join(td.get_text(strip=True) for td in row.find_all('td', class_='textoNegro')[1:]))\n",
    "    return ' | '.join(education_data)\n",
    "\n",
    "# Función para extraer los enlaces a las iniciativas políticas\n",
    "def extract_policy_links(soup):\n",
    "    return [complete_url(a['href']) for a in soup.select('td.Estilo51 a.linkBlancoSin')]\n",
    "\n",
    "# Función para extraer la información de las políticas propuestas\n",
    "def extract_policies(policy_links):\n",
    "    policies_data = []\n",
    "    for link in policy_links:\n",
    "        policy_page_soup = fetch_page(link)\n",
    "        # Se corrige el selector CSS basado en la estructura HTML proporcionada\n",
    "        policy_descriptions = policy_page_soup.select('td[valign=\"top\"].Estilo69 span.Estilo71')\n",
    "        for policy in policy_descriptions:\n",
    "            # Extraer solo el texto de las políticas, sin el número y suscriptor\n",
    "            if policy.find('b') is not None:  # Si hay un elemento en negrita (número de la política), se ignora\n",
    "                policy_text = policy.get_text(separator=' ', strip=True)\n",
    "                policies_data.append(policy_text)\n",
    "    return ' | '.join(policies_data)\n",
    "\n",
    "# Función para extraer la información de cada diputado\n",
    "def extract_deputy_info(deputy_url):\n",
    "    soup = fetch_page(deputy_url)\n",
    "    education = extract_education(soup)\n",
    "    policy_links = extract_policy_links(soup)\n",
    "    policies = extract_policies(policy_links)\n",
    "    return {'Education': education, 'Policies': policies}\n",
    "\n",
    "# URL inicial con la lista de diputados\n",
    "base_url = 'https://sitllx.diputados.gob.mx/listado_diputados_gpnp.php?tipot=TOTAL'\n",
    "\n",
    "# Obtener la lista de diputados y sus URLs\n",
    "deputies_list = [(dep.text, complete_url(dep['href'])) for dep in fetch_page(base_url).select('td > a.linkVerde')]\n",
    "\n",
    "# Configurar el ThreadPoolExecutor para extraer la información de manera concurrente\n",
    "deputies_info = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    future_to_deputy = {executor.submit(extract_deputy_info, deputy_data[1]): deputy_data[0] for deputy_data in deputies_list}\n",
    "    for future in concurrent.futures.as_completed(future_to_deputy):\n",
    "        deputy_name = future_to_deputy[future]\n",
    "        try:\n",
    "            deputy_info = future.result()\n",
    "            deputies_info.append({\n",
    "                'Name': deputy_name,\n",
    "                **deputy_info\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {deputy_name}: {e}\")\n",
    "\n",
    "# Crear DataFrame de pandas con la información extraída\n",
    "df = pd.DataFrame(deputies_info)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         nombre educacion  \\\n",
      "0           Dip. Martía Teresa Alanís Domínguez        []   \n",
      "1    Dip. María del Consuelo Argüelles Arellano        []   \n",
      "2                  Dip. Gerardo Amezola Fonceca        []   \n",
      "3                  Dip. Pedro Armendáriz García        []   \n",
      "4                    Dip. Gerardo Aranda Orozco        []   \n",
      "..                                          ...       ...   \n",
      "495                  Dip. Armando García Méndez        []   \n",
      "496               Dip. Humberto López Lena Cruz        []   \n",
      "497      Dip. Elsa de Guadalupe Conde Rodríguez        []   \n",
      "498          Dip. Santiago Gustavo Pedro Cortés        []   \n",
      "499               Dip. Aida Marina Arvizu Rivas        []   \n",
      "\n",
      "                                           iniciativas  \n",
      "0                                                   []  \n",
      "1    [[1Proyecto de decreto que reforma el Artículo...  \n",
      "2    [[1Proyecto de decreto que reforma los artícul...  \n",
      "3    [[1Proyecto de decreto que reforma y adiciona ...  \n",
      "4    [[1Proyecto de decreto que reforma y adiciona ...  \n",
      "..                                                 ...  \n",
      "495  [[1Proyecto de decreto que deroga el párrafo c...  \n",
      "496  [[1Proyecto de decreto que reforma el artículo...  \n",
      "497  [[1Proyecto de decreto que reforma el artículo...  \n",
      "498  [[1Proyecto de decreto que reforma y adiciona ...  \n",
      "499  [[1Proyecto de decreto que reforma los numeral...  \n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# URL de la página con la lista de diputados\n",
    "url_base = 'https://sitllx.diputados.gob.mx/listado_diputados_gpnp.php?tipot=TOTAL'\n",
    "\n",
    "# Función para obtener el objeto BeautifulSoup de una página de forma concurrente\n",
    "def obtener_html(url):\n",
    "    with requests.Session() as session:  # Utiliza una sesión para reutilizar la conexión\n",
    "        respuesta = session.get(url)\n",
    "        respuesta.raise_for_status()  # Lanzar error si la solicitud falla\n",
    "        return BeautifulSoup(respuesta.content, 'html.parser')\n",
    "\n",
    "# Función para extraer la lista de diputados y sus URLs\n",
    "def extraer_lista_diputados(soup):\n",
    "    diputados = []\n",
    "    for enlace in soup.select('a.linkVerde'):\n",
    "        nombre = enlace.get_text(strip=True)\n",
    "        url_diputado = 'https://sitllx.diputados.gob.mx/' + enlace['href']\n",
    "        diputados.append({'nombre': nombre, 'url': url_diputado})\n",
    "    return diputados\n",
    "\n",
    "# Función para extraer la información educativa de la página de un diputado\n",
    "def extraer_informacion_educativa(soup):\n",
    "    educacion = []\n",
    "    seccion_escolaridad = soup.find('td', text='ESCOLARIDAD')\n",
    "    # Verificar que se encontró la sección antes de continuar\n",
    "    if seccion_escolaridad:\n",
    "        tabla_escolaridad = seccion_escolaridad.find_next('table')\n",
    "        if tabla_escolaridad:\n",
    "            for fila in tabla_escolaridad.find_all('tr'):\n",
    "                celdas = fila.find_all('td')\n",
    "                if celdas and len(celdas) == 3:\n",
    "                    grado, campo, periodo = [celda.get_text(strip=True) for celda in celdas]\n",
    "                    educacion.append({'grado': grado, 'campo': campo, 'periodo': periodo})\n",
    "    return educacion\n",
    "\n",
    "# Función para extraer los enlaces a las iniciativas de un diputado\n",
    "def extraer_enlaces_iniciativas(soup):\n",
    "    enlace_iniciativas = soup.find('a', text='Iniciativas')\n",
    "    if enlace_iniciativas:\n",
    "        url_iniciativas = 'https://sitllx.diputados.gob.mx/' + enlace_iniciativas['href']\n",
    "        soup_iniciativas = obtener_html(url_iniciativas)\n",
    "        enlaces_periodos = soup_iniciativas.select('a.linkVerde')\n",
    "        iniciativas = [extraer_texto_iniciativas('https://sitllx.diputados.gob.mx/' + enlace['href']) for enlace in enlaces_periodos]\n",
    "        return iniciativas\n",
    "    return []\n",
    "\n",
    "# Función para extraer el texto de las iniciativas de un periodo de sesiones\n",
    "def extraer_texto_iniciativas(url_periodo):\n",
    "    soup_periodo = obtener_html(url_periodo)\n",
    "    textos = []\n",
    "    for iniciativa in soup_periodo.select('span.Estilo71'):\n",
    "        texto = iniciativa.get_text(strip=True)\n",
    "        if texto:\n",
    "            textos.append(texto)\n",
    "    return textos\n",
    "\n",
    "# Función para obtener la información de un diputado\n",
    "def obtener_info_diputado(url):\n",
    "    soup_diputado = obtener_html(url)\n",
    "    nombre = soup_diputado.find('span', class_='Estilo67').text.strip()\n",
    "    educacion = extraer_informacion_educativa(soup_diputado)\n",
    "    iniciativas = extraer_enlaces_iniciativas(soup_diputado)\n",
    "    return {\n",
    "        'nombre': nombre,\n",
    "        'educacion': educacion,\n",
    "        'iniciativas': iniciativas\n",
    "    }\n",
    "\n",
    "# Función principal para extraer la información de todos los diputados\n",
    "def extraer_informacion_diputados_concurrent():\n",
    "    soup_lista = obtener_html(url_base)\n",
    "    lista_diputados = extraer_lista_diputados(soup_lista)\n",
    "    urls_diputados = [diputado['url'] for diputado in lista_diputados]\n",
    "    \n",
    "    datos_diputados = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_url = {executor.submit(obtener_info_diputado, url): url for url in urls_diputados}\n",
    "        for future in as_completed(future_to_url):\n",
    "            try:\n",
    "                datos_diputados.append(future.result())\n",
    "            except Exception as exc:\n",
    "                print(f'Hubo un problema con la URL {future_to_url[future]}: {exc}')\n",
    "    \n",
    "    return pd.DataFrame(datos_diputados)\n",
    "\n",
    "# Ejecutar la función principal y mostrar/guardar el DataFrame resultante\n",
    "df_diputados = extraer_informacion_diputados_concurrent()\n",
    "print(df_diputados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hubo un problema con la URL https://sitllx.diputados.gob.mx/curricula.php?dipt=262: HTTPSConnectionPool(host='sitllx.diputados.gob.mx', port=443): Max retries exceeded with url: /iniciativas_por_pernp.php?iddipt=262&pert=5 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001E853360810>, 'Connection to sitllx.diputados.gob.mx timed out. (connect timeout=None)'))\n",
      "Hubo un problema con la URL https://sitllx.diputados.gob.mx/curricula.php?dipt=455: HTTPSConnectionPool(host='sitllx.diputados.gob.mx', port=443): Max retries exceeded with url: /iniciativas_por_pernp.php?iddipt=455&pert=6 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001E8546D1450>, 'Connection to sitllx.diputados.gob.mx timed out. (connect timeout=None)'))\n",
      "Hubo un problema con la URL https://sitllx.diputados.gob.mx/curricula.php?dipt=434: HTTPSConnectionPool(host='sitllx.diputados.gob.mx', port=443): Max retries exceeded with url: /iniciativas_por_pernp.php?iddipt=434&pert=7 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001E8536F56D0>, 'Connection to sitllx.diputados.gob.mx timed out. (connect timeout=None)'))\n",
      "                                         nombre  \\\n",
      "0           Dip. Martía Teresa Alanís Domínguez   \n",
      "1    Dip. María del Consuelo Argüelles Arellano   \n",
      "2                  Dip. Gerardo Amezola Fonceca   \n",
      "3                  Dip. Pedro Armendáriz García   \n",
      "4               Dip. María Elena Álvarez Bernal   \n",
      "..                                          ...   \n",
      "492                  Dip. Armando García Méndez   \n",
      "493               Dip. Humberto López Lena Cruz   \n",
      "494          Dip. Santiago Gustavo Pedro Cortés   \n",
      "495      Dip. Elsa de Guadalupe Conde Rodríguez   \n",
      "496               Dip. Aida Marina Arvizu Rivas   \n",
      "\n",
      "                                             educacion  \\\n",
      "0                                                   []   \n",
      "1    [{'grado': 'Licenciatura', 'campo': 'Sistemas ...   \n",
      "2    [{'grado': 'Nivel Medio Superior', 'campo': ''...   \n",
      "3    [{'grado': 'Licenciatura', 'campo': 'Relacione...   \n",
      "4    [{'grado': 'Profesor Normalista', 'campo': 'Pr...   \n",
      "..                                                 ...   \n",
      "492  [{'grado': 'Técnica', 'campo': '', 'periodo': ...   \n",
      "493  [{'grado': 'Técnica', 'campo': '', 'periodo': ...   \n",
      "494  [{'grado': 'Pasante', 'campo': 'Economía', 'pe...   \n",
      "495  [{'grado': 'Licenciatura', 'campo': 'Psicologí...   \n",
      "496  [{'grado': 'Licenciatura', 'campo': 'Relacione...   \n",
      "\n",
      "                                           iniciativas  \n",
      "0                                                   []  \n",
      "1    [[1Proyecto de decreto que reforma el Artículo...  \n",
      "2    [[1Proyecto de decreto que reforma los artícul...  \n",
      "3    [[1Proyecto de decreto que reforma y adiciona ...  \n",
      "4    [[1Proyecto de decreto que reforma el artículo...  \n",
      "..                                                 ...  \n",
      "492  [[1Proyecto de decreto que deroga el párrafo c...  \n",
      "493  [[1Proyecto de decreto que reforma el artículo...  \n",
      "494  [[1Proyecto de decreto que reforma y adiciona ...  \n",
      "495  [[1Proyecto de decreto que reforma el artículo...  \n",
      "496  [[1Proyecto de decreto que reforma los numeral...  \n",
      "\n",
      "[497 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# URL de la página con la lista de diputados\n",
    "url_base = 'https://sitllx.diputados.gob.mx/listado_diputados_gpnp.php?tipot=TOTAL'\n",
    "\n",
    "# Función para obtener el objeto BeautifulSoup de una página de forma concurrente\n",
    "def obtener_html(url):\n",
    "    with requests.Session() as session:  # Utiliza una sesión para reutilizar la conexión\n",
    "        respuesta = session.get(url)\n",
    "        respuesta.raise_for_status()  # Lanzar error si la solicitud falla\n",
    "        return BeautifulSoup(respuesta.content, 'html.parser')\n",
    "\n",
    "# Función para extraer la lista de diputados y sus URLs\n",
    "def extraer_lista_diputados(soup):\n",
    "    diputados = []\n",
    "    for enlace in soup.select('a.linkVerde'):\n",
    "        nombre = enlace.get_text(strip=True)\n",
    "        url_diputado = 'https://sitllx.diputados.gob.mx/' + enlace['href']\n",
    "        diputados.append({'nombre': nombre, 'url': url_diputado})\n",
    "    return diputados\n",
    "\n",
    "# Función para extraer la información educativa de la página de un diputado\n",
    "def extraer_informacion_educativa(soup):\n",
    "    educacion = []\n",
    "    # Encuentra todas las entradas después del encabezado 'ESCOLARIDAD'\n",
    "    seccion_escolaridad = soup.find('td', class_='TitulosVerde', text='ESCOLARIDAD')\n",
    "    if seccion_escolaridad:\n",
    "        # La sección de escolaridad está en la misma tabla, pero después del título 'ESCOLARIDAD'\n",
    "        entradas_escolaridad = seccion_escolaridad.find_all_next('tr')\n",
    "        for entrada in entradas_escolaridad:\n",
    "            celdas = entrada.find_all('td', class_='textoNegro')\n",
    "            # Podría haber filas que no pertenecen a la sección escolaridad, como 'TRAYECTORIA POLÍTICA'\n",
    "            # Así que verifica si la fila pertenece a la sección escolaridad\n",
    "            if celdas and len(celdas) >= 2:  # Asumiendo que hay al menos dos celdas (grado y campo)\n",
    "                # Extraer el grado, campo y periodo si están presentes\n",
    "                grado = celdas[0].get_text(strip=True) if len(celdas) > 0 else ''\n",
    "                campo = celdas[1].get_text(strip=True) if len(celdas) > 1 else ''\n",
    "                periodo = celdas[2].get_text(strip=True) if len(celdas) > 2 else ''\n",
    "                educacion.append({'grado': grado, 'campo': campo, 'periodo': periodo})\n",
    "            # Si se encuentra un nuevo encabezado, se detiene la extracción\n",
    "            if entrada.find('td', class_='TitulosVerde'):\n",
    "                break\n",
    "    return educacion\n",
    "\n",
    "# Función para extraer los enlaces a las iniciativas de un diputado\n",
    "def extraer_enlaces_iniciativas(soup):\n",
    "    enlace_iniciativas = soup.find('a', text='Iniciativas')\n",
    "    if enlace_iniciativas:\n",
    "        url_iniciativas = 'https://sitllx.diputados.gob.mx/' + enlace_iniciativas['href']\n",
    "        soup_iniciativas = obtener_html(url_iniciativas)\n",
    "        enlaces_periodos = soup_iniciativas.select('a.linkVerde')\n",
    "        iniciativas = [extraer_texto_iniciativas('https://sitllx.diputados.gob.mx/' + enlace['href']) for enlace in enlaces_periodos]\n",
    "        return iniciativas\n",
    "    return []\n",
    "\n",
    "# Función para extraer el texto de las iniciativas de un periodo de sesiones\n",
    "def extraer_texto_iniciativas(url_periodo):\n",
    "    soup_periodo = obtener_html(url_periodo)\n",
    "    textos = []\n",
    "    for iniciativa in soup_periodo.select('span.Estilo71'):\n",
    "        texto = iniciativa.get_text(strip=True)\n",
    "        if texto:\n",
    "            textos.append(texto)\n",
    "    return textos\n",
    "\n",
    "# Función para obtener la información de un diputado\n",
    "def obtener_info_diputado(url):\n",
    "    soup_diputado = obtener_html(url)\n",
    "    nombre = soup_diputado.find('span', class_='Estilo67').text.strip()\n",
    "    educacion = extraer_informacion_educativa(soup_diputado)\n",
    "    iniciativas = extraer_enlaces_iniciativas(soup_diputado)\n",
    "    return {\n",
    "        'nombre': nombre,\n",
    "        'educacion': educacion,\n",
    "        'iniciativas': iniciativas\n",
    "    }\n",
    "\n",
    "# Función principal para extraer la información de todos los diputados\n",
    "def extraer_informacion_diputados_concurrent():\n",
    "    soup_lista = obtener_html(url_base)\n",
    "    lista_diputados = extraer_lista_diputados(soup_lista)\n",
    "    urls_diputados = [diputado['url'] for diputado in lista_diputados]\n",
    "    \n",
    "    datos_diputados = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_url = {executor.submit(obtener_info_diputado, url): url for url in urls_diputados}\n",
    "        for future in as_completed(future_to_url):\n",
    "            try:\n",
    "                datos_diputados.append(future.result())\n",
    "            except Exception as exc:\n",
    "                print(f'Hubo un problema con la URL {future_to_url[future]}: {exc}')\n",
    "    \n",
    "    return pd.DataFrame(datos_diputados)\n",
    "\n",
    "# Ejecutar la función principal y mostrar/guardar el DataFrame resultante\n",
    "df_diputados = extraer_informacion_diputados_concurrent()\n",
    "print(df_diputados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado como: diputados.csv\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que 'df_diputados' es tu DataFrame\n",
    "\n",
    "# Convertir el DataFrame a CSV\n",
    "nombre_archivo = \"diputados.csv\"\n",
    "df_diputados.to_csv(nombre_archivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Archivo guardado como: {nombre_archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# URL de la página con la lista de diputados\n",
    "url_base = 'https://sitllxiii.diputados.gob.mx/listado_diputados_gpnp.php?tipot=TOTAL'\n",
    "\n",
    "# Función para obtener el objeto BeautifulSoup de una página de forma concurrente\n",
    "def obtener_html(url):\n",
    "    with requests.Session() as session:  # Utiliza una sesión para reutilizar la conexión\n",
    "        respuesta = session.get(url)\n",
    "        respuesta.raise_for_status()  # Lanzar error si la solicitud falla\n",
    "        return BeautifulSoup(respuesta.content, 'html.parser')\n",
    "\n",
    "# Función para extraer la lista de diputados y sus URLs\n",
    "def extraer_lista_diputados(soup):\n",
    "    diputados = []\n",
    "    for enlace in soup.select('a.linkVerde'):\n",
    "        nombre = enlace.get_text(strip=True)\n",
    "        url_diputado = 'https://sitllxiii.diputados.gob.mx/' + enlace['href']\n",
    "        diputados.append({'nombre': nombre, 'url': url_diputado})\n",
    "    return diputados\n",
    "\n",
    "# Función para extraer la información educativa de la página de un diputado\n",
    "def extraer_informacion_educativa(soup):\n",
    "    educacion = []\n",
    "    # Encuentra todas las entradas después del encabezado 'ESCOLARIDAD'\n",
    "    seccion_escolaridad = soup.find('td', class_='TitulosVerde', text='ESCOLARIDAD')\n",
    "    if seccion_escolaridad:\n",
    "        # La sección de escolaridad está en la misma tabla, pero después del título 'ESCOLARIDAD'\n",
    "        entradas_escolaridad = seccion_escolaridad.find_all_next('tr')\n",
    "        for entrada in entradas_escolaridad:\n",
    "            celdas = entrada.find_all('td', class_='textoNegro')\n",
    "            # Podría haber filas que no pertenecen a la sección escolaridad, como 'TRAYECTORIA POLÍTICA'\n",
    "            # Así que verifica si la fila pertenece a la sección escolaridad\n",
    "            if celdas and len(celdas) >= 2:  # Asumiendo que hay al menos dos celdas (grado y campo)\n",
    "                # Extraer el grado, campo y periodo si están presentes\n",
    "                grado = celdas[0].get_text(strip=True) if len(celdas) > 0 else ''\n",
    "                campo = celdas[1].get_text(strip=True) if len(celdas) > 1 else ''\n",
    "                periodo = celdas[2].get_text(strip=True) if len(celdas) > 2 else ''\n",
    "                educacion.append({'grado': grado, 'campo': campo, 'periodo': periodo})\n",
    "            # Si se encuentra un nuevo encabezado, se detiene la extracción\n",
    "            if entrada.find('td', class_='TitulosVerde'):\n",
    "                break\n",
    "    return educacion\n",
    "\n",
    "# Función para extraer los enlaces a las iniciativas de un diputado\n",
    "def extraer_enlaces_iniciativas(soup):\n",
    "    enlace_iniciativas = soup.find('a', text='Iniciativas')\n",
    "    if enlace_iniciativas:\n",
    "        url_iniciativas = 'https://sitllxiii.diputados.gob.mx/' + enlace_iniciativas['href']\n",
    "        soup_iniciativas = obtener_html(url_iniciativas)\n",
    "        enlaces_periodos = soup_iniciativas.select('a.linkVerde')\n",
    "        iniciativas = [extraer_texto_iniciativas('https://sitllxiii.diputados.gob.mx/' + enlace['href']) for enlace in enlaces_periodos]\n",
    "        return iniciativas\n",
    "    return []\n",
    "\n",
    "# Función para extraer el texto de las iniciativas de un periodo de sesiones\n",
    "def extraer_texto_iniciativas(url_periodo):\n",
    "    soup_periodo = obtener_html(url_periodo)\n",
    "    textos = []\n",
    "    for iniciativa in soup_periodo.select('span.Estilo71'):\n",
    "        texto = iniciativa.get_text(strip=True)\n",
    "        if texto:\n",
    "            textos.append(texto)\n",
    "    return textos\n",
    "\n",
    "# Función para obtener la información de un diputado\n",
    "def obtener_info_diputado(url):\n",
    "    soup_diputado = obtener_html(url)\n",
    "    nombre = soup_diputado.find('span', class_='Estilo67').text.strip()\n",
    "    educacion = extraer_informacion_educativa(soup_diputado)\n",
    "    iniciativas = extraer_enlaces_iniciativas(soup_diputado)\n",
    "    entidad = soup_diputado.find('span', text='Entidad:').find_next('td').text.strip()\n",
    "    return {\n",
    "        'nombre': nombre,\n",
    "        'entidad': entidad,\n",
    "        'educacion': educacion,\n",
    "        'iniciativas': iniciativas\n",
    "    }\n",
    "\n",
    "# Función principal para extraer la información de todos los diputados\n",
    "def extraer_informacion_diputados_concurrent():\n",
    "    soup_lista = obtener_html(url_base)\n",
    "    lista_diputados = extraer_lista_diputados(soup_lista)\n",
    "    urls_diputados = [diputado['url'] for diputado in lista_diputados]\n",
    "    \n",
    "    datos_diputados = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_url = {executor.submit(obtener_info_diputado, url): url for url in urls_diputados}\n",
    "        for future in as_completed(future_to_url):\n",
    "            try:\n",
    "                datos_diputados.append(future.result())\n",
    "            except Exception as exc:\n",
    "                print(f'Hubo un problema con la URL {future_to_url[future]}: {exc}')\n",
    "    \n",
    "    return pd.DataFrame(datos_diputados)\n",
    "\n",
    "# Ejecutar la función principal y mostrar/guardar el DataFrame resultante\n",
    "df_diputados = extraer_informacion_diputados_concurrent()\n",
    "print(df_diputados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado como: diputados_1.3.csv\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que 'df_diputados' es tu DataFrame\n",
    "\n",
    "# Convertir el DataFrame a CSV\n",
    "nombre_archivo = \"diputados_1.3.csv\"\n",
    "df_diputados.to_csv(nombre_archivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Archivo guardado como: {nombre_archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hubo un problema con la URL https://sitllxiii.diputados.gob.mx/./curricula.php?dipt=200: HTTPSConnectionPool(host='sitllxiii.diputados.gob.mx', port=443): Max retries exceeded with url: /iniciativas_por_pernplxiii.php?iddipt=200&pert=9 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DCA005C350>, 'Connection to sitllxiii.diputados.gob.mx timed out. (connect timeout=None)'))\n",
      "Hubo un problema con la URL https://sitllxiii.diputados.gob.mx/./curricula.php?dipt=104: HTTPSConnectionPool(host='sitllxiii.diputados.gob.mx', port=443): Max retries exceeded with url: /iniciativas_por_pernplxiii.php?iddipt=104&pert=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DC9F593410>, 'Connection to sitllxiii.diputados.gob.mx timed out. (connect timeout=None)'))\n",
      "Hubo un problema con la URL https://sitllxiii.diputados.gob.mx/./curricula.php?dipt=420: HTTPSConnectionPool(host='sitllxiii.diputados.gob.mx', port=443): Max retries exceeded with url: /iniciativas_por_pernplxiii.php?iddipt=420&pert=9 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DC9E94BF90>, 'Connection to sitllxiii.diputados.gob.mx timed out. (connect timeout=None)'))\n",
      "          nombre                                 entidad  \\\n",
      "0    Iniciativas   Tabasco|Circunscripción:3|Curul:G-212   \n",
      "1    Iniciativas    México|Circunscripción:5|Curul:I-315   \n",
      "2    Iniciativas        Veracruz|Distrito:17|Curul:L-448   \n",
      "3    Iniciativas         Tlaxcala|Distrito:2|Curul:M-496   \n",
      "4    Iniciativas        Veracruz|Distrito:16|Curul:P-507   \n",
      "..           ...                                     ...   \n",
      "492  Iniciativas  Coahuila|Circunscripción:2|Curul:J-354   \n",
      "493  Iniciativas  Veracruz|Circunscripción:3|Curul:H-263   \n",
      "494  Iniciativas     Quintana Roo|Distrito:1|Curul:F-174   \n",
      "495  Iniciativas           Oaxaca|Distrito:8|Curul:E-151   \n",
      "496  Iniciativas         Veracruz|Distrito:7|Curul:H-255   \n",
      "\n",
      "                                             educacion  \\\n",
      "0                                                   []   \n",
      "1    [{'grado': 'Licenciatura', 'campo': 'Contadurí...   \n",
      "2    [{'grado': 'Licenciatura', 'campo': 'Prensa Es...   \n",
      "3    [{'grado': 'Maestría', 'campo': 'Políticas Púb...   \n",
      "4    [{'grado': 'Maestría', 'campo': 'Ciencias pena...   \n",
      "..                                                 ...   \n",
      "492  [{'grado': 'Maestría', 'campo': 'Administració...   \n",
      "493  [{'grado': 'Posgrado', 'campo': 'Ciencias Polí...   \n",
      "494  [{'grado': 'Licenciatura', 'campo': 'Turismo I...   \n",
      "495  [{'grado': 'Maestría', 'campo': 'Contribucione...   \n",
      "496  [{'grado': 'Licenciatura', 'campo': 'Derecho c...   \n",
      "\n",
      "                                           iniciativas  \n",
      "0                                                   []  \n",
      "1    [[1Proyecto de decreto por el que se declara e...  \n",
      "2    [[1Proyecto de decreto que reforma el artículo...  \n",
      "3    [[1Proyecto de decreto que reforma los artícul...  \n",
      "4    [[1Proyecto de decreto que reforma y adiciona ...  \n",
      "..                                                 ...  \n",
      "492  [[1Proyecto de decreto que reforma y adiciona ...  \n",
      "493  [[1Proyecto de decreto que reforma el artículo...  \n",
      "494  [[1Proyecto de decreto que reforma el artículo...  \n",
      "495  [[1Proyecto de decreto que reforma el artículo...  \n",
      "496  [[1Proyecto de decreto que reforma el artículo...  \n",
      "\n",
      "[497 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# URL de la página con la lista de diputados\n",
    "url_base = 'https://sitllxiii.diputados.gob.mx/listado_diputados_gpnp.php?tipot=TOTAL'\n",
    "\n",
    "# Función para obtener el objeto BeautifulSoup de una página de forma concurrente\n",
    "def obtener_html(url):\n",
    "    with requests.Session() as session:  # Utiliza una sesión para reutilizar la conexión\n",
    "        respuesta = session.get(url)\n",
    "        respuesta.raise_for_status()  # Lanzar error si la solicitud falla\n",
    "        return BeautifulSoup(respuesta.content, 'html.parser')\n",
    "\n",
    "# Función para extraer la lista de diputados y sus URLs\n",
    "def extraer_lista_diputados(soup):\n",
    "    diputados = []\n",
    "    for enlace in soup.select('a.linkVerde'):\n",
    "        nombre = enlace.get_text(strip=True)\n",
    "        url_diputado = 'https://sitllxiii.diputados.gob.mx/' + enlace['href']\n",
    "        diputados.append({'nombre': nombre, 'url': url_diputado})\n",
    "    return diputados\n",
    "\n",
    "# Función para extraer la información educativa de la página de un diputado\n",
    "def extraer_informacion_educativa(soup):\n",
    "    educacion = []\n",
    "    # Encuentra todas las entradas después del encabezado 'ESCOLARIDAD'\n",
    "    seccion_escolaridad = soup.find('td', class_='TitulosVerde', text='ESCOLARIDAD')\n",
    "    if seccion_escolaridad:\n",
    "        # La sección de escolaridad está en la misma tabla, pero después del título 'ESCOLARIDAD'\n",
    "        entradas_escolaridad = seccion_escolaridad.find_all_next('tr')\n",
    "        for entrada in entradas_escolaridad:\n",
    "            celdas = entrada.find_all('td', class_='textoNegro')\n",
    "            # Podría haber filas que no pertenecen a la sección escolaridad, como 'TRAYECTORIA POLÍTICA'\n",
    "            # Así que verifica si la fila pertenece a la sección escolaridad\n",
    "            if celdas and len(celdas) >= 2:  # Asumiendo que hay al menos dos celdas (grado y campo)\n",
    "                # Extraer el grado, campo y periodo si están presentes\n",
    "                grado = celdas[0].get_text(strip=True) if len(celdas) > 0 else ''\n",
    "                campo = celdas[1].get_text(strip=True) if len(celdas) > 1 else ''\n",
    "                periodo = celdas[2].get_text(strip=True) if len(celdas) > 2 else ''\n",
    "                educacion.append({'grado': grado, 'campo': campo, 'periodo': periodo})\n",
    "            # Si se encuentra un nuevo encabezado, se detiene la extracción\n",
    "            if entrada.find('td', class_='TitulosVerde'):\n",
    "                break\n",
    "    return educacion\n",
    "\n",
    "# Función para extraer los enlaces a las iniciativas de un diputado\n",
    "def extraer_enlaces_iniciativas(soup):\n",
    "    enlace_iniciativas = soup.find('a', text='Iniciativas')\n",
    "    if enlace_iniciativas:\n",
    "        url_iniciativas = 'https://sitllxiii.diputados.gob.mx/' + enlace_iniciativas['href']\n",
    "        soup_iniciativas = obtener_html(url_iniciativas)\n",
    "        enlaces_periodos = soup_iniciativas.select('a.linkVerde')\n",
    "        iniciativas = [extraer_texto_iniciativas('https://sitllxiii.diputados.gob.mx/' + enlace['href']) for enlace in enlaces_periodos]\n",
    "        return iniciativas\n",
    "    return []\n",
    "\n",
    "# Función para extraer el texto de las iniciativas de un periodo de sesiones\n",
    "def extraer_texto_iniciativas(url_periodo):\n",
    "    soup_periodo = obtener_html(url_periodo)\n",
    "    textos = []\n",
    "    for iniciativa in soup_periodo.select('span.Estilo71'):\n",
    "        texto = iniciativa.get_text(strip=True)\n",
    "        if texto:\n",
    "            textos.append(texto)\n",
    "    return textos\n",
    "\n",
    "# Función para extraer la entidad de la página de un diputado\n",
    "def extraer_entidad(soup):\n",
    "    # Intenta encontrar el contenedor específico que incluye la entidad\n",
    "    # buscando por texto y considerando la estructura general\n",
    "    contenedor_entidad = soup.find(\"td\", text=lambda x: x and \"Entidad:\" in x)\n",
    "    \n",
    "    if contenedor_entidad:\n",
    "        # Buscar el siguiente elemento hermano que contendría el nombre de la entidad\n",
    "        entidad = contenedor_entidad.find_next_sibling(\"td\")\n",
    "        if entidad:\n",
    "            # Extraer y limpiar el texto de la entidad\n",
    "            texto_entidad = entidad.get_text(strip=True)\n",
    "            return texto_entidad\n",
    "    return \"No disponible\"  # Retorna esto si no se encuentra la entidad\n",
    "\n",
    "# Función para obtener la información completa de un diputado\n",
    "def obtener_info_diputado(url):\n",
    "    soup_diputado = obtener_html(url)\n",
    "    \n",
    "    # Extraer el nombre del diputado\n",
    "    elemento_nombre = soup_diputado.find('font', face='Arial, Helvetica, sans-serif')\n",
    "    nombre = elemento_nombre.get_text(strip=True) if elemento_nombre else 'Nombre no disponible'\n",
    "    \n",
    "    # Extraer la entidad del diputado\n",
    "    entidad = extraer_entidad(soup_diputado)\n",
    "    educacion = extraer_informacion_educativa(soup_diputado)\n",
    "    iniciativas = extraer_enlaces_iniciativas(soup_diputado)\n",
    "    return {\n",
    "        'nombre': nombre,\n",
    "        'entidad': entidad,\n",
    "        'educacion': educacion,\n",
    "        'iniciativas': iniciativas\n",
    "    }\n",
    "\n",
    "# Función principal para extraer la información de todos los diputados\n",
    "def extraer_informacion_diputados_concurrent():\n",
    "    soup_lista = obtener_html(url_base)\n",
    "    lista_diputados = extraer_lista_diputados(soup_lista)\n",
    "    urls_diputados = [diputado['url'] for diputado in lista_diputados]\n",
    "    \n",
    "    datos_diputados = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_url = {executor.submit(obtener_info_diputado, url): url for url in urls_diputados}\n",
    "        for future in as_completed(future_to_url):\n",
    "            try:\n",
    "                diputado_info = future.result()\n",
    "                if diputado_info:\n",
    "                    datos_diputados.append(diputado_info)\n",
    "            except Exception as exc:\n",
    "                print(f'Hubo un problema con la URL {future_to_url[future]}: {exc}')\n",
    "    \n",
    "    return pd.DataFrame(datos_diputados)\n",
    "\n",
    "# Ejecutar la función principal y mostrar/guardar el DataFrame resultante\n",
    "df_diputados = extraer_informacion_diputados_concurrent()\n",
    "print(df_diputados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   nombre       entidad  \\\n",
      "0         Dip. Erubiel Lorenzo Alonso Que       Tabasco   \n",
      "1    Dip. María Guadalupe Alcántara Rojas        México   \n",
      "2          Dip. Antonio Tarek Abdala Saad      Veracruz   \n",
      "3       Dip. Edith Anabel Alvarado Varela      Tlaxcala   \n",
      "4               Dip. Fidel Almanza Monroy        México   \n",
      "..                                    ...           ...   \n",
      "495           Dip. Javier Guerrero García      Coahuila   \n",
      "496              Dip. Adriana Sarur Torre      Veracruz   \n",
      "497          Dip. José Luis Toledo Medina  Quintana Roo   \n",
      "498          Dip. Francisco Martínez Neri        Oaxaca   \n",
      "499            Dip. Edgar Spinoso Carrera      Veracruz   \n",
      "\n",
      "                                             educacion  \\\n",
      "0                                                   []   \n",
      "1    [{'grado': 'Licenciatura', 'campo': 'Contadurí...   \n",
      "2    [{'grado': 'Licenciatura', 'campo': 'Prensa Es...   \n",
      "3    [{'grado': 'Maestría', 'campo': 'Políticas Púb...   \n",
      "4    [{'grado': 'Conferencia', 'campo': 'Ciclo Inte...   \n",
      "..                                                 ...   \n",
      "495  [{'grado': 'Maestría', 'campo': 'Administració...   \n",
      "496  [{'grado': 'Posgrado', 'campo': 'Ciencias Polí...   \n",
      "497  [{'grado': 'Licenciatura', 'campo': 'Turismo I...   \n",
      "498  [{'grado': 'Maestría', 'campo': 'Contribucione...   \n",
      "499  [{'grado': 'Licenciatura', 'campo': 'Derecho c...   \n",
      "\n",
      "                                           iniciativas  \n",
      "0                                                   []  \n",
      "1    [[1Proyecto de decreto por el que se declara e...  \n",
      "2    [[1Proyecto de decreto que reforma el artículo...  \n",
      "3    [[1Proyecto de decreto que reforma los artícul...  \n",
      "4    [[1Proyecto de decreto que reforma el artículo...  \n",
      "..                                                 ...  \n",
      "495  [[1Proyecto de decreto que reforma y adiciona ...  \n",
      "496  [[1Proyecto de decreto que reforma el artículo...  \n",
      "497  [[1Proyecto de decreto que reforma el artículo...  \n",
      "498  [[1Proyecto de decreto que reforma el artículo...  \n",
      "499  [[1Proyecto de decreto que reforma el artículo...  \n",
      "\n",
      "[500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# URL de la página con la lista de diputados\n",
    "url_base = 'https://sitllxiii.diputados.gob.mx/listado_diputados_gpnp.php?tipot=TOTAL'\n",
    "\n",
    "# Función para obtener el objeto BeautifulSoup de una página de forma concurrente\n",
    "def obtener_html(url):\n",
    "    with requests.Session() as session:  # Utiliza una sesión para reutilizar la conexión\n",
    "        respuesta = session.get(url)\n",
    "        respuesta.raise_for_status()  # Lanzar error si la solicitud falla\n",
    "        return BeautifulSoup(respuesta.content, 'html.parser')\n",
    "\n",
    "# Función para extraer la lista de diputados y sus URLs\n",
    "def extraer_lista_diputados(soup):\n",
    "    diputados = []\n",
    "    for enlace in soup.select('a.linkVerde'):\n",
    "        nombre = enlace.get_text(strip=True)\n",
    "        url_diputado = 'https://sitllxiii.diputados.gob.mx/' + enlace['href']\n",
    "        diputados.append({'nombre': nombre, 'url': url_diputado})\n",
    "    return diputados\n",
    "\n",
    "# Función para extraer la información educativa de la página de un diputado\n",
    "def extraer_informacion_educativa(soup):\n",
    "    educacion = []\n",
    "    # Encuentra todas las entradas después del encabezado 'ESCOLARIDAD'\n",
    "    seccion_escolaridad = soup.find('td', class_='TitulosVerde', text='ESCOLARIDAD')\n",
    "    if seccion_escolaridad:\n",
    "        # La sección de escolaridad está en la misma tabla, pero después del título 'ESCOLARIDAD'\n",
    "        entradas_escolaridad = seccion_escolaridad.find_all_next('tr')\n",
    "        for entrada in entradas_escolaridad:\n",
    "            celdas = entrada.find_all('td', class_='textoNegro')\n",
    "            # Podría haber filas que no pertenecen a la sección escolaridad, como 'TRAYECTORIA POLÍTICA'\n",
    "            # Así que verifica si la fila pertenece a la sección escolaridad\n",
    "            if celdas and len(celdas) >= 2:  # Asumiendo que hay al menos dos celdas (grado y campo)\n",
    "                # Extraer el grado, campo y periodo si están presentes\n",
    "                grado = celdas[0].get_text(strip=True) if len(celdas) > 0 else ''\n",
    "                campo = celdas[1].get_text(strip=True) if len(celdas) > 1 else ''\n",
    "                periodo = celdas[2].get_text(strip=True) if len(celdas) > 2 else ''\n",
    "                educacion.append({'grado': grado, 'campo': campo, 'periodo': periodo})\n",
    "            # Si se encuentra un nuevo encabezado, se detiene la extracción\n",
    "            if entrada.find('td', class_='TitulosVerde'):\n",
    "                break\n",
    "    return educacion\n",
    "\n",
    "# Función para extraer los enlaces a las iniciativas de un diputado\n",
    "def extraer_enlaces_iniciativas(soup):\n",
    "    enlace_iniciativas = soup.find('a', text='Iniciativas')\n",
    "    if enlace_iniciativas:\n",
    "        url_iniciativas = 'https://sitllxiii.diputados.gob.mx/' + enlace_iniciativas['href']\n",
    "        soup_iniciativas = obtener_html(url_iniciativas)\n",
    "        enlaces_periodos = soup_iniciativas.select('a.linkVerde')\n",
    "        iniciativas = [extraer_texto_iniciativas('https://sitllxiii.diputados.gob.mx/' + enlace['href']) for enlace in enlaces_periodos]\n",
    "        return iniciativas\n",
    "    return []\n",
    "\n",
    "# Función para extraer el texto de las iniciativas de un periodo de sesiones\n",
    "def extraer_texto_iniciativas(url_periodo):\n",
    "    soup_periodo = obtener_html(url_periodo)\n",
    "    textos = []\n",
    "    for iniciativa in soup_periodo.select('span.Estilo71'):\n",
    "        texto = iniciativa.get_text(strip=True)\n",
    "        if texto:\n",
    "            textos.append(texto)\n",
    "    return textos\n",
    "\n",
    "# Función para extraer la entidad de la página de un diputado\n",
    "def extraer_entidad(soup):\n",
    "    try:\n",
    "        entidad_texto = soup.find(text=lambda text: \"Entidad:\" in text).find_next()\n",
    "        entidad = entidad_texto.get_text(strip=True) if entidad_texto else \"No disponible\"\n",
    "        return entidad.split(\"|\")[0].strip()\n",
    "    except AttributeError:\n",
    "        return \"No disponible\"\n",
    "\n",
    "\n",
    "# Función para obtener la información completa de un diputado\n",
    "def obtener_info_diputado(url):\n",
    "    soup_diputado = obtener_html(url)\n",
    "    \n",
    "    # Corrección en la extracción del nombre del diputado\n",
    "    elemento_nombre = soup_diputado.find('strong', text=lambda t: \"Dip.\" in t)\n",
    "    nombre = elemento_nombre.get_text(strip=True) if elemento_nombre else 'Nombre no disponible'\n",
    "    \n",
    "    entidad = extraer_entidad(soup_diputado)\n",
    "    \n",
    "    # Las siguientes líneas se mantienen sin cambios\n",
    "    educacion = extraer_informacion_educativa(soup_diputado)\n",
    "    iniciativas = extraer_enlaces_iniciativas(soup_diputado)\n",
    "    \n",
    "    return {\n",
    "        'nombre': nombre,\n",
    "        'entidad': entidad,\n",
    "        'educacion': educacion,\n",
    "        'iniciativas': iniciativas\n",
    "    }\n",
    "\n",
    "def extraer_informacion_diputados_concurrent():\n",
    "    soup_lista = obtener_html(url_base)\n",
    "    lista_diputados = extraer_lista_diputados(soup_lista)\n",
    "    urls_diputados = [diputado['url'] for diputado in lista_diputados]\n",
    "    \n",
    "    datos_diputados = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_url = {executor.submit(obtener_info_diputado, url): url for url in urls_diputados}\n",
    "        for future in as_completed(future_to_url):\n",
    "            try:\n",
    "                diputado_info = future.result()\n",
    "                if diputado_info:\n",
    "                    datos_diputados.append(diputado_info)\n",
    "            except Exception as exc:\n",
    "                print(f'Hubo un problema con la URL {future_to_url[future]}: {exc}')\n",
    "    \n",
    "    return pd.DataFrame(datos_diputados)\n",
    "\n",
    "# Ejecutar la función principal y mostrar/guardar el DataFrame resultante\n",
    "df_diputados = extraer_informacion_diputados_concurrent()\n",
    "print(df_diputados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado como: diputados_1.4.csv\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que 'df_diputados' es tu DataFrame\n",
    "\n",
    "# Convertir el DataFrame a CSV\n",
    "nombre_archivo = \"diputados_1.4.csv\"\n",
    "df_diputados.to_csv(nombre_archivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Archivo guardado como: {nombre_archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
