{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      nombre  \\\n",
      "0           Dip. Odette Nayeri Almazán Muñoz   \n",
      "1           Dip. Rosa Maria Alvarado Murguía   \n",
      "2          Dip. Karla Yuritzi Almazán Burgos   \n",
      "3        Dip. Martha Alicia Arreola Martinez   \n",
      "4              Dip. Carol Antonio Altamirano   \n",
      "..                                       ...   \n",
      "495           Dip. Laura Lynn Fernández Piña   \n",
      "496  Dip. Luis Ángel Xariel Espinosa Cházaro   \n",
      "497                       Dip. Gabriela Sodi   \n",
      "498              Dip. Susana Prieto Terrazas   \n",
      "499     Dip. Claudia Gabriela Olvera Higuera   \n",
      "\n",
      "                                             educacion  \\\n",
      "0                                                   []   \n",
      "1                                                   []   \n",
      "2    [{'grado': 'Diplomado', 'campo': 'Ciencias Pol...   \n",
      "3                                                   []   \n",
      "4    [{'grado': 'Licenciatura', 'campo': 'Derecho',...   \n",
      "..                                                 ...   \n",
      "495  [{'grado': 'Licenciatura', 'campo': 'Mercadote...   \n",
      "496                                                 []   \n",
      "497  [{'grado': 'Licenciatura', 'campo': 'Historia ...   \n",
      "498                                                 []   \n",
      "499                                                 []   \n",
      "\n",
      "                                           iniciativas  \n",
      "0    [[], [1Proyecto de decreto por el que se expid...  \n",
      "1    [[], [1Proyecto de decreto por el que se expid...  \n",
      "2    [[], [1Proyecto de decreto por el que se expid...  \n",
      "3    [[], [1Proyecto de decreto que reforma los art...  \n",
      "4    [[], [1Proyecto de decreto por el que se expid...  \n",
      "..                                                 ...  \n",
      "495  [[], [1Proyecto de decreto que adiciona el art...  \n",
      "496  [[], [1Proyecto de decreto por el que se expid...  \n",
      "497  [[], [1Proyecto de decreto que reforma los art...  \n",
      "498  [[], [1Proyecto de decreto por el que se expid...  \n",
      "499  [[], [1Proyecto de decreto que reforma el artí...  \n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# URL de la página con la lista de diputados\n",
    "url_base = 'https://sitl.diputados.gob.mx/LXV_leg/listado_diputados_gpnp.php?tipot=TOTAL'\n",
    "\n",
    "# Función para obtener el objeto BeautifulSoup de una página de forma concurrente\n",
    "def obtener_html(url):\n",
    "    with requests.Session() as session:  # Utiliza una sesión para reutilizar la conexión\n",
    "        respuesta = session.get(url, timeout=10)\n",
    "        respuesta.raise_for_status()  # Lanzar error si la solicitud falla\n",
    "        return BeautifulSoup(respuesta.content, 'html.parser')\n",
    "\n",
    "# Función para extraer la lista de diputados y sus URLs\n",
    "def extraer_lista_diputados(soup):\n",
    "    diputados = []\n",
    "    for enlace in soup.select('a.Estilolinks'):\n",
    "        nombre = enlace.get_text(strip=True)\n",
    "        url_diputado = 'https://sitl.diputados.gob.mx/LXV_leg/' + enlace['href']\n",
    "        diputados.append({'nombre': nombre, 'url': url_diputado})\n",
    "    return diputados\n",
    "\n",
    "# Función para extraer la información educativa de la página de un diputado\n",
    "def extraer_informacion_educativa(soup):\n",
    "    educacion = []\n",
    "    # Encuentra todas las entradas después del encabezado 'ESCOLARIDAD'\n",
    "    seccion_escolaridad = soup.find('td', class_='TitulosVerde', text='ESCOLARIDAD')\n",
    "    if seccion_escolaridad:\n",
    "        # La sección de escolaridad está en la misma tabla, pero después del título 'ESCOLARIDAD'\n",
    "        entradas_escolaridad = seccion_escolaridad.find_all_next('tr')\n",
    "        for entrada in entradas_escolaridad:\n",
    "            celdas = entrada.find_all('td', class_='textoNegro')\n",
    "            # Podría haber filas que no pertenecen a la sección escolaridad, como 'TRAYECTORIA POLÍTICA'\n",
    "            # Así que verifica si la fila pertenece a la sección escolaridad\n",
    "            if celdas and len(celdas) >= 2:  # Asumiendo que hay al menos dos celdas (grado y campo)\n",
    "                # Extraer el grado, campo y periodo si están presentes\n",
    "                grado = celdas[0].get_text(strip=True) if len(celdas) > 0 else ''\n",
    "                campo = celdas[1].get_text(strip=True) if len(celdas) > 1 else ''\n",
    "                periodo = celdas[2].get_text(strip=True) if len(celdas) > 2 else ''\n",
    "                educacion.append({'grado': grado, 'campo': campo, 'periodo': periodo})\n",
    "            # Si se encuentra un nuevo encabezado, se detiene la extracción\n",
    "            if entrada.find('td', class_='TitulosVerde'):\n",
    "                break\n",
    "    return educacion\n",
    "\n",
    "# Función para extraer los enlaces a las iniciativas de un diputado\n",
    "def extraer_enlaces_iniciativas(soup):\n",
    "    enlace_iniciativas = soup.find('a', text='Iniciativas')\n",
    "    if enlace_iniciativas:\n",
    "        url_iniciativas = 'https://sitl.diputados.gob.mx/LXV_leg/' + enlace_iniciativas['href']\n",
    "        soup_iniciativas = obtener_html(url_iniciativas)\n",
    "        enlaces_periodos = soup_iniciativas.select('a.estilolinks')\n",
    "        iniciativas = [extraer_texto_iniciativas('https://sitl.diputados.gob.mx/LXV_leg/' + enlace['href']) for enlace in enlaces_periodos]\n",
    "        return iniciativas\n",
    "    return []\n",
    "\n",
    "# Función para extraer el texto de las iniciativas de un periodo de sesiones\n",
    "def extraer_texto_iniciativas(url_periodo):\n",
    "    soup_periodo = obtener_html(url_periodo)\n",
    "    textos = []\n",
    "    for iniciativa in soup_periodo.select('span.Estiloparrafoc'):\n",
    "        texto = iniciativa.get_text(strip=True)\n",
    "        if texto:\n",
    "            textos.append(texto)\n",
    "    return textos\n",
    "\n",
    "# Función para obtener la información de un diputado\n",
    "def obtener_info_diputado(url):\n",
    "    soup_diputado = obtener_html(url)\n",
    "    nombre_element = soup_diputado.find(lambda tag: tag.name == \"td\" and tag.get(\"height\") == \"23\" and tag.strong)\n",
    "    if nombre_element and nombre_element.strong:\n",
    "        nombre = nombre_element.strong.text.strip()\n",
    "    else:\n",
    "        nombre = \"Nombre no encontrado\"\n",
    "    educacion = extraer_informacion_educativa(soup_diputado)\n",
    "    iniciativas = extraer_enlaces_iniciativas(soup_diputado)\n",
    "    return {\n",
    "        'nombre': nombre,\n",
    "        'educación': educacion,\n",
    "        'iniciativas': iniciativas\n",
    "    }\n",
    "\n",
    "# Función principal para extraer la información de todos los diputados\n",
    "def extraer_informacion_diputados_concurrent():\n",
    "    soup_lista = obtener_html(url_base)\n",
    "    lista_diputados = extraer_lista_diputados(soup_lista)\n",
    "    urls_diputados = [diputado['url'] for diputado in lista_diputados]\n",
    "    \n",
    "    datos_diputados = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_url = {executor.submit(obtener_info_diputado, url): url for url in urls_diputados}\n",
    "        for future in as_completed(future_to_url):\n",
    "            try:\n",
    "                datos_diputados.append(future.result())\n",
    "            except Exception as exc:\n",
    "                print(f'Hubo un problema con la URL {future_to_url[future]}: {exc}')\n",
    "    \n",
    "    return pd.DataFrame(datos_diputados)\n",
    "\n",
    "# Ejecutar la función principal y mostrar/guardar el DataFrame resultante\n",
    "df_diputados = extraer_informacion_diputados_concurrent()\n",
    "print(df_diputados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado como: diputados_1.5.csv\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que 'df_diputados' es tu DataFrame\n",
    "\n",
    "# Convertir el DataFrame a CSV\n",
    "nombre_archivo = \"diputados_1.5.csv\"\n",
    "df_diputados.to_csv(nombre_archivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Archivo guardado como: {nombre_archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       nombre                entidad  \\\n",
      "0    Dip. Carol Antonio Altamirano (LICENCIA)                Oaxaca    \n",
      "1            Dip. Odette Nayeri Almazán Muñoz                Puebla    \n",
      "2            Dip. Maria Isabel Alfaro Morales               Hidalgo    \n",
      "3         Dip. Martha Alicia Arreola Martinez               Durango    \n",
      "4           Dip. Karla Yuritzi Almazán Burgos                México    \n",
      "..                                        ...                    ...   \n",
      "495            Dip. Laura Lynn Fernández Piña          Quintana Roo    \n",
      "496                        Dip. Gabriela Sodi      Ciudad de México    \n",
      "497   Dip. Luis Ángel Xariel Espinosa Cházaro  Entidad no encontrada   \n",
      "498               Dip. Susana Prieto Terrazas  Entidad no encontrada   \n",
      "499      Dip. Claudia Gabriela Olvera Higuera                México    \n",
      "\n",
      "                                             educación  \\\n",
      "0    [{'grado': 'Licenciatura', 'campo': 'Derecho',...   \n",
      "1                                                   []   \n",
      "2    [{'grado': 'Seminario', 'campo': 'Aerobico Pro...   \n",
      "3                                                   []   \n",
      "4    [{'grado': 'Diplomado', 'campo': 'Ciencias Pol...   \n",
      "..                                                 ...   \n",
      "495  [{'grado': 'Licenciatura', 'campo': 'Mercadote...   \n",
      "496  [{'grado': 'Licenciatura', 'campo': 'Historia ...   \n",
      "497                                                 []   \n",
      "498                                                 []   \n",
      "499                                                 []   \n",
      "\n",
      "                                           iniciativas  \n",
      "0    [[], [1Proyecto de decreto por el que se expid...  \n",
      "1    [[], [1Proyecto de decreto por el que se expid...  \n",
      "2    [[], [1Proyecto de decreto por el que se expid...  \n",
      "3    [[], [1Proyecto de decreto que reforma los art...  \n",
      "4    [[], [1Proyecto de decreto por el que se expid...  \n",
      "..                                                 ...  \n",
      "495  [[], [1Proyecto de decreto que adiciona el art...  \n",
      "496  [[], [1Proyecto de decreto que reforma los art...  \n",
      "497  [[], [1Proyecto de decreto por el que se expid...  \n",
      "498  [[], [1Proyecto de decreto por el que se expid...  \n",
      "499  [[], [1Proyecto de decreto que reforma el artí...  \n",
      "\n",
      "[500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "# URL de la página con la lista de diputados\n",
    "url_base = 'https://sitl.diputados.gob.mx/LXV_leg/listado_diputados_gpnp.php?tipot=TOTAL'\n",
    "\n",
    "# Configurar la sesión con reintentos\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[502, 503, 504])\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "# Función para obtener el objeto BeautifulSoup de una página de forma concurrente\n",
    "def obtener_html(url):\n",
    "    respuesta = session.get(url, timeout=5)\n",
    "    respuesta.raise_for_status()\n",
    "    return BeautifulSoup(respuesta.content, 'html.parser')\n",
    "\n",
    "# Función para extraer la lista de diputados y sus URLs\n",
    "def extraer_lista_diputados(soup):\n",
    "    diputados = []\n",
    "    for enlace in soup.select('a.Estilolinks'):\n",
    "        nombre = enlace.get_text(strip=True)\n",
    "        url_diputado = 'https://sitl.diputados.gob.mx/LXV_leg/' + enlace['href']\n",
    "        diputados.append({'nombre': nombre, 'url': url_diputado})\n",
    "    return diputados\n",
    "\n",
    "# Función ajustada para extraer correctamente la entidad del diputado\n",
    "def extraer_entidad(soup):\n",
    "    entidad_texto = soup.find(text=\"Entidad:\")\n",
    "    entidad = entidad_texto.find_next().text.strip() if entidad_texto else \"Entidad no encontrada\"\n",
    "    entidad = entidad.split('\\n')[0]  # Solo toma la primera línea que es el nombre de la entidad\n",
    "    return entidad\n",
    "\n",
    "# Función para extraer la información educativa de la página de un diputado\n",
    "def extraer_informacion_educativa(soup):\n",
    "    educacion = []\n",
    "    # Encuentra todas las entradas después del encabezado 'ESCOLARIDAD'\n",
    "    seccion_escolaridad = soup.find('td', class_='TitulosVerde', text='ESCOLARIDAD')\n",
    "    if seccion_escolaridad:\n",
    "        # La sección de escolaridad está en la misma tabla, pero después del título 'ESCOLARIDAD'\n",
    "        entradas_escolaridad = seccion_escolaridad.find_all_next('tr')\n",
    "        for entrada in entradas_escolaridad:\n",
    "            celdas = entrada.find_all('td', class_='textoNegro')\n",
    "            # Podría haber filas que no pertenecen a la sección escolaridad, como 'TRAYECTORIA POLÍTICA'\n",
    "            # Así que verifica si la fila pertenece a la sección escolaridad\n",
    "            if celdas and len(celdas) >= 2:  # Asumiendo que hay al menos dos celdas (grado y campo)\n",
    "                # Extraer el grado, campo y periodo si están presentes\n",
    "                grado = celdas[0].get_text(strip=True) if len(celdas) > 0 else ''\n",
    "                campo = celdas[1].get_text(strip=True) if len(celdas) > 1 else ''\n",
    "                periodo = celdas[2].get_text(strip=True) if len(celdas) > 2 else ''\n",
    "                educacion.append({'grado': grado, 'campo': campo, 'periodo': periodo})\n",
    "            # Si se encuentra un nuevo encabezado, se detiene la extracción\n",
    "            if entrada.find('td', class_='TitulosVerde'):\n",
    "                break\n",
    "    return educacion\n",
    "\n",
    "# Función para extraer los enlaces a las iniciativas de un diputado\n",
    "def extraer_enlaces_iniciativas(soup):\n",
    "    enlace_iniciativas = soup.find('a', text='Iniciativas')\n",
    "    if enlace_iniciativas:\n",
    "        url_iniciativas = 'https://sitl.diputados.gob.mx/LXV_leg/' + enlace_iniciativas['href']\n",
    "        soup_iniciativas = obtener_html(url_iniciativas)\n",
    "        enlaces_periodos = soup_iniciativas.select('a.estilolinks')\n",
    "        iniciativas = [extraer_texto_iniciativas('https://sitl.diputados.gob.mx/LXV_leg/' + enlace['href']) for enlace in enlaces_periodos]\n",
    "        return iniciativas\n",
    "    return []\n",
    "\n",
    "# Función para extraer el texto de las iniciativas de un periodo de sesiones\n",
    "def extraer_texto_iniciativas(url_periodo):\n",
    "    soup_periodo = obtener_html(url_periodo)\n",
    "    textos = []\n",
    "    for iniciativa in soup_periodo.select('span.Estiloparrafoc'):\n",
    "        texto = iniciativa.get_text(strip=True)\n",
    "        if texto:\n",
    "            textos.append(texto)\n",
    "    return textos\n",
    "\n",
    "# Función para obtener la información de un diputado\n",
    "def obtener_info_diputado(url):\n",
    "    try:\n",
    "        soup_diputado = obtener_html(url)\n",
    "        nombre_element = soup_diputado.find(lambda tag: tag.name == \"font\" and \"Dip.\" in tag.text)\n",
    "        nombre = nombre_element.text.strip() if nombre_element else \"Nombre no encontrado\"\n",
    "        entidad = extraer_entidad(soup_diputado)\n",
    "        educacion = extraer_informacion_educativa(soup_diputado)\n",
    "        iniciativas = extraer_enlaces_iniciativas(soup_diputado)\n",
    "        return {\n",
    "            'nombre': nombre,\n",
    "            'entidad': entidad,\n",
    "            'educación': educacion,\n",
    "            'iniciativas': iniciativas\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f'Error al procesar {url}: {e}')\n",
    "        return None  # Devolver None en caso de error\n",
    "\n",
    "# Función principal para extraer la información de todos los diputados\n",
    "def extraer_informacion_diputados_concurrent():\n",
    "    soup_lista = obtener_html(url_base)\n",
    "    lista_diputados = extraer_lista_diputados(soup_lista)\n",
    "    urls_diputados = [diputado['url'] for diputado in lista_diputados]\n",
    "\n",
    "    datos_diputados = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(obtener_info_diputado, url) for url in urls_diputados]\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                datos_diputados.append(result)\n",
    "\n",
    "    return pd.DataFrame(datos_diputados)\n",
    "\n",
    "# Ejecutar la función principal y mostrar/guardar el DataFrame resultante\n",
    "df_diputados = extraer_informacion_diputados_concurrent()\n",
    "print(df_diputados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado como: diputados_1.5.csv\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que 'df_diputados' es tu DataFrame\n",
    "\n",
    "# Convertir el DataFrame a CSV\n",
    "nombre_archivo = \"diputados_1.5.csv\"\n",
    "df_diputados.to_csv(nombre_archivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Archivo guardado como: {nombre_archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
